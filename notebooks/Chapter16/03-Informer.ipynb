{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c696685-98bc-4cd1-8792-8f6b250ab956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ManuJoseph\\OneDrive - Thoucentric\\Work\\Projects\\Playground\\AdvancedTimeSeriesForecastingBook\\Github\\Modern-Time-Series-Forecasting-with-Python-\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94bfdac4-3813-4ec0-8817-aef3b09932a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ManuJoseph\\OneDrive - Thoucentric\\Work\\Projects\\Playground\\AdvancedTimeSeriesForecastingBook\\Github\\Modern-Time-Series-Forecasting-with-Python-\\src\\utils\\data_utils.py:6: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from src.forecasting.ml_forecasting import (\n",
    "    MissingValueConfig,\n",
    "    calculate_metrics,\n",
    ")\n",
    "from src.utils import plotting_utils\n",
    "from tqdm.autonotebook import tqdm\n",
    "from src.forecasting.ml_forecasting import calculate_metrics\n",
    "from src.utils import ts_utils\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "np.random.seed(42)\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fe3dbd6-c494-455b-a2bb-573bc634c627",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"imgs/chapter_15\", exist_ok=True)\n",
    "os.makedirs(\"notebooks/Chapter15/saved_weights\", exist_ok=True)\n",
    "preprocessed = Path(\"data/london_smart_meters/preprocessed\")\n",
    "output = Path(\"data/london_smart_meters/output\")\n",
    "# Make True to select a subsample. Helps with faster training.\n",
    "TRAIN_SUBSAMPLE = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9b4a30-c264-499a-b767-cedc511faf52",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf53a95c-0b8b-45d9-8e2b-d657dddedc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_plot(fig, legends=None, xlabel=\"Time\", ylabel=\"Value\", title=\"\", font_size=15):\n",
    "    if legends:\n",
    "        names = cycle(legends)\n",
    "        fig.for_each_trace(lambda t: t.update(name=next(names)))\n",
    "    fig.update_layout(\n",
    "        autosize=False,\n",
    "        width=900,\n",
    "        height=500,\n",
    "        title_text=title,\n",
    "        title={\"x\": 0.5, \"xanchor\": \"center\", \"yanchor\": \"top\"},\n",
    "        titlefont={\"size\": 20},\n",
    "        legend_title=None,\n",
    "        legend=dict(\n",
    "            font=dict(size=font_size),\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=0.98,\n",
    "            xanchor=\"right\",\n",
    "            x=1,\n",
    "        ),\n",
    "        yaxis=dict(\n",
    "            title_text=ylabel,\n",
    "            titlefont=dict(size=font_size),\n",
    "            tickfont=dict(size=font_size),\n",
    "        ),\n",
    "        xaxis=dict(\n",
    "            title_text=xlabel,\n",
    "            titlefont=dict(size=font_size),\n",
    "            tickfont=dict(size=font_size),\n",
    "        )\n",
    "    )\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5c15835-d868-4284-83d4-e842d7eedd8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from itertools import cycle\n",
    "\n",
    "\n",
    "def plot_forecast(pred_df, forecast_columns, forecast_display_names=None):\n",
    "    if forecast_display_names is None:\n",
    "        forecast_display_names = forecast_columns\n",
    "    else:\n",
    "        assert len(forecast_columns) == len(forecast_display_names)\n",
    "    mask = ~pred_df[forecast_columns[0]].isnull()\n",
    "    colors = [\n",
    "        \"rgba(\" + \",\".join([str(c) for c in plotting_utils.hex_to_rgb(c)]) + \",<alpha>)\"\n",
    "        for c in px.colors.qualitative.Plotly\n",
    "    ]\n",
    "    act_color = colors[0]\n",
    "    colors = cycle(colors[1:])\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=pred_df[mask].index,\n",
    "            y=pred_df[mask].energy_consumption,\n",
    "            mode=\"lines\",\n",
    "            line=dict(color=act_color.replace(\"<alpha>\", \"0.9\")),\n",
    "            name=\"Actual Consumption\",\n",
    "        )\n",
    "    )\n",
    "    for col, display_col in zip(forecast_columns, forecast_display_names):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=pred_df[mask].index,\n",
    "                y=pred_df.loc[mask, col],\n",
    "                mode=\"lines\",\n",
    "                line=dict(dash=\"dot\", color=next(colors).replace(\"<alpha>\", \"1\")),\n",
    "                name=display_col,\n",
    "            )\n",
    "        )\n",
    "    return fig\n",
    "\n",
    "def highlight_abs_min(s, props=''):\n",
    "    return np.where(s.abs() == np.nanmin(np.abs(s.values)), props, '')\n",
    "\n",
    "def evaluate_forecast(pred_df, train_data, fc_column, name, target_name=\"energy_consumption\"):\n",
    "    metric_l = []\n",
    "    for _id in tqdm(pred_df.index.get_level_values(0).unique(), desc=\"Calculating metrics...\"):\n",
    "        target = pred_df.xs(_id)[[target_name]]\n",
    "        _y_pred = pred_df.xs(_id)[[fc_column]]\n",
    "        history = train_data.xs(_id)[[target_name]]\n",
    "        # display(history.tail())\n",
    "        # display(_y_pred.head())\n",
    "        # display(target.head())\n",
    "        metric_l.append(\n",
    "            calculate_metrics(target, _y_pred, name=name, y_train=history)\n",
    "        )\n",
    "    eval_metrics_df = pd.DataFrame(metric_l)\n",
    "    agg_metrics = {\n",
    "            \"Algorithm\": name,\n",
    "            \"MAE\": np.nanmean(np.abs(pred_df[fc_column]-pred_df[target_name])),\n",
    "            \"MSE\": np.nanmean(np.power(pred_df[fc_column]-pred_df[target_name], 2)),\n",
    "            \"meanMASE\": eval_metrics_df.loc[:, \"MASE\"].mean(),\n",
    "            \"Forecast Bias\": 100*(np.nansum(pred_df[fc_column])-np.nansum(pred_df[target_name]))/np.nansum(pred_df[target_name])\n",
    "    }\n",
    "    return agg_metrics, eval_metrics_df\n",
    "\n",
    "from pytorch_lightning.utilities.cloud_io import load as pl_load\n",
    "\n",
    "def load_weights(model, weight_path):\n",
    "    state_dict = pl_load(weight_path)\n",
    "    model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ea8470c-7a36-416e-865b-105b5aa21e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_day_ahead_fc(x):\n",
    "    x[f'{tag}_one_day'] = 0\n",
    "    for i in range(0, len(x)-48,48):\n",
    "        # print(i)\n",
    "        x.iloc[i:i+48,-1] = x[[col for col in x.columns if col.startswith(f\"{tag}_step\")]].iloc[i].values\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9806f8e4-9f66-41ff-894c-cbf27045a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "FeatureConfig = namedtuple(\n",
    "    \"FeatureConfig\",\n",
    "    [\n",
    "        \"target\",\n",
    "        \"index_cols\",\n",
    "        \"static_categoricals\",\n",
    "        \"static_reals\",\n",
    "        \"time_varying_known_categoricals\",\n",
    "        \"time_varying_known_reals\",\n",
    "        \"time_varying_unknown_reals\",\n",
    "        \"group_ids\"\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d116bb-3924-4c83-94d6-530df0d1b8f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "415a63e4-408e-4ebd-864e-091dba77ba01",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    #Reading the missing value imputed and train test split data\n",
    "    train_df = pd.read_parquet(preprocessed/\"selected_blocks_train_missing_imputed_feature_engg.parquet\")\n",
    "    # Read in the Validation dataset as test_df so that we predict on it\n",
    "    test_df = pd.read_parquet(preprocessed/\"selected_blocks_val_missing_imputed_feature_engg.parquet\")\n",
    "    # test_df = pd.read_parquet(preprocessed/\"selected_blocks_test_missing_imputed_feature_engg.parquet\")\n",
    "except FileNotFoundError:\n",
    "    display(HTML(\"\"\"\n",
    "    <div class=\"alert alert-block alert-warning\">\n",
    "    <b>Warning!</b> File not found. Please make sure you have run 01-Feature Engineering.ipynb in Chapter06\n",
    "    </div>\n",
    "    \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc656a09-6164-4671-96f0-0699681c3161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub sampling\n"
     ]
    }
   ],
   "source": [
    "# To run on smaller set of data for daster iteration.\n",
    "if TRAIN_SUBSAMPLE:\n",
    "    print(\"sub sampling\")\n",
    "    SAMPLE = 10\n",
    "    sampled_LCLids = pd.Series(train_df.LCLid.unique().remove_unused_categories().categories).sample(SAMPLE, random_state=99).tolist()\n",
    "    train_df = train_df.loc[train_df.LCLid.isin(sampled_LCLids)]\n",
    "    test_df = test_df.loc[test_df.LCLid.isin(sampled_LCLids)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2715dd9-2eaa-4d4a-bac1-9a1f392fb2ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Defining the different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b37505e-5275-448a-8b3b-7d045c3505f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_config = FeatureConfig(\n",
    "    target=\"energy_consumption\",\n",
    "    index_cols=[\"LCLid\", \"timestamp\"],\n",
    "    static_categoricals=[\n",
    "        \"LCLid\",\n",
    "        \"stdorToU\",\n",
    "        \"Acorn\",\n",
    "        \"Acorn_grouped\",\n",
    "        \"file\",\n",
    "    ],  # Categoricals which does not change with time\n",
    "    static_reals=[],  # Reals which does not change with time\n",
    "    time_varying_known_categoricals=[  # Categoricals which change with time\n",
    "        \"holidays\",\n",
    "        \"timestamp_Dayofweek\",\n",
    "    ],\n",
    "    time_varying_known_reals=[  # Reals which change with time\n",
    "        \"apparentTemperature\",\n",
    "    ],  \n",
    "    time_varying_unknown_reals=[  # Reals which change with time, but we don't have the future. Like the target\n",
    "        \"energy_consumption\"\n",
    "    ],  \n",
    "    group_ids=[  # Feature or list of features which uniquely identifies each entity\n",
    "        \"LCLid\"\n",
    "    ],  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76544a8-045d-45e0-9ca8-de39bca1da5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Creating a continuous time index for PyTorch Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff08cafc-9adf-41f7-aba1-9a7526f0774e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining train and test with a flag\n",
    "train_df['train'] = True\n",
    "test_df['train'] = False\n",
    "data = pd.concat([train_df, test_df])\n",
    "del train_df, test_df\n",
    "# Adding the time index\n",
    "data['time_idx'] = data.timestamp.apply(lambda x: x.value)\n",
    "diff = data.iloc[1]['time_idx'] - data.iloc[0]['time_idx']\n",
    "data[\"_min_time_idx\"] = data.groupby(\"LCLid\", observed=True)['time_idx'].transform(\"min\")\n",
    "data['time_idx'] = ((data['time_idx']-data['_min_time_idx'])/diff).astype(int)\n",
    "data.drop(columns=\"_min_time_idx\", inplace=True)\n",
    "# separating to train and test\n",
    "train_df = data.loc[data.train]\n",
    "test_df = data.loc[~data.train]\n",
    "del data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2b1470-40ee-49af-a29e-17a44bad2fc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Converting the categoricals to `object` dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1be41828-5877-456b-ab0a-736852a84695",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\n",
    "    feat_config.static_categoricals + feat_config.time_varying_known_categoricals\n",
    "] = train_df[\n",
    "    feat_config.static_categoricals + feat_config.time_varying_known_categoricals\n",
    "].astype(\n",
    "    \"object\"\n",
    ")\n",
    "\n",
    "test_df[\n",
    "    feat_config.static_categoricals + feat_config.time_varying_known_categoricals\n",
    "] = test_df[\n",
    "    feat_config.static_categoricals + feat_config.time_varying_known_categoricals\n",
    "].astype(\n",
    "    \"object\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55015911-fe45-477e-a509-ba0fae3c071a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c39b19fc-cff1-4aa4-a346-1958922d18ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pressure                                          True\n",
       "energy_consumption_lag_1                          True\n",
       "energy_consumption_lag_2                          True\n",
       "energy_consumption_lag_3                          True\n",
       "energy_consumption_lag_4                          True\n",
       "energy_consumption_lag_5                          True\n",
       "energy_consumption_lag_46                         True\n",
       "energy_consumption_lag_47                         True\n",
       "energy_consumption_lag_48                         True\n",
       "energy_consumption_lag_49                         True\n",
       "energy_consumption_lag_50                         True\n",
       "energy_consumption_lag_334                        True\n",
       "energy_consumption_lag_335                        True\n",
       "energy_consumption_lag_336                        True\n",
       "energy_consumption_lag_337                        True\n",
       "energy_consumption_lag_338                        True\n",
       "energy_consumption_rolling_3_mean                 True\n",
       "energy_consumption_rolling_3_std                  True\n",
       "energy_consumption_rolling_6_mean                 True\n",
       "energy_consumption_rolling_6_std                  True\n",
       "energy_consumption_rolling_12_mean                True\n",
       "energy_consumption_rolling_12_std                 True\n",
       "energy_consumption_rolling_48_mean                True\n",
       "energy_consumption_rolling_48_std                 True\n",
       "energy_consumption_48_seasonal_rolling_3_mean     True\n",
       "energy_consumption_48_seasonal_rolling_3_std      True\n",
       "energy_consumption_336_seasonal_rolling_3_mean    True\n",
       "energy_consumption_336_seasonal_rolling_3_std     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking missing values\n",
    "n = train_df.isna().any()\n",
    "n[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "221e3353-5d1a-4747-a349-66dbd39ba182",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We aren't using any of these features. So let it be"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24118217-9f80-4017-924d-9cc2f7e156f9",
   "metadata": {},
   "source": [
    "# Training Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f885fc4-8d75-4e82-a7f9-5dd16688e7e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "pl.seed_everything(42)\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import RMSE, MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6db1b45-25db-444b-8a6d-b35e301a80df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the TensorBoard notebook extension\n",
    "# %load_ext tensorboard\n",
    "# os.makedirs(\"lightning_logs\", exist_ok=True)\n",
    "# %tensorboard --logdir lightning_logs/\n",
    "\n",
    "# Or start the tensorboard in a separate command prompt/terminal using\n",
    "# tensorboard --logdir lightning_logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f26ace8-0934-43b7-a272-cc2784f89276",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "111ced86-ec78-4b4a-a7b5-b41fef55c03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_prediction_length = 48\n",
    "max_encoder_length = 48*2\n",
    "batch_size = 512  # set this to a value which your GPU can handle\n",
    "train_model = True # Set this to True to train model. Else will load saved models ! Warning! Training on full dataset takes 3-6 hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "deac0b52-709c-4425-9322-cbe3bda1ea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = \"Informer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0fd2576-8aff-458f-af8a-d2f2365dbdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_record = []\n",
    "individual_metrics = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f09ae16-1fed-45f4-a66d-f356f0ef0d06",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Creating dataframes for train, val and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "342b92be-1a8c-4ce6-9dc2-f14b2aa103fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2013-12-31 23:30:00'), Timestamp('2014-01-01 00:00:00'))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.timestamp.max(), test_df.timestamp.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26b1d390-51b2-4050-94c7-311afe7df792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History Min: 2013-12-30 00:00:00 | Max: 2013-12-31 23:30:00 | Length: 96\n"
     ]
    }
   ],
   "source": [
    "#Adding 2 days of history (48*2) to create the samples\n",
    "history_cutoff = train_df.timestamp.max() - pd.Timedelta(2, \"D\")\n",
    "hist_df = train_df[train_df.timestamp>history_cutoff]\n",
    "print(f\"History Min: {hist_df.timestamp.min()} | Max: {hist_df.timestamp.max()} | Length: {len(hist_df.timestamp.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "644006c3-d659-4dd7-95e7-c932c1ccb686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Timestamps:\n",
      "Train Max: 2013-12-30 23:30:00 | Val History Min and Max: (Timestamp('2013-12-28 23:30:00'), Timestamp('2013-12-30 23:30:00')) | Val Min and Max: (Timestamp('2013-12-31 00:00:00'), Timestamp('2013-12-31 23:30:00'))\n",
      "Val History Size: 97 | Val Size: 48\n"
     ]
    }
   ],
   "source": [
    "#Keeping 1 days aside as a validation set\n",
    "cutoff = train_df.timestamp.max() - pd.Timedelta(1, \"D\")\n",
    "#Adding 2 days of history (48*2) to create the samples\n",
    "history_cutoff = train_df.timestamp.max() - pd.Timedelta(3, \"D\")\n",
    "val_history = train_df[(train_df.timestamp>=history_cutoff)&(train_df.timestamp<=cutoff)].reset_index(drop=True)\n",
    "val_df = train_df[train_df.timestamp>cutoff].reset_index(drop=True)\n",
    "train_df = train_df[train_df.timestamp<=cutoff].reset_index(drop=True)\n",
    "print(\"Split Timestamps:\")\n",
    "print(f\"Train Max: {train_df.timestamp.max()} | Val History Min and Max: {val_history.timestamp.min(), val_history.timestamp.max()} | Val Min and Max: {val_df.timestamp.min(), val_df.timestamp.max()}\")\n",
    "print(f\"Val History Size: {len(val_history.timestamp.unique())} | Val Size: {len(val_df.timestamp.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8271fe02-6b1e-4857-b7e9-2e3e4f8d40c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = test_df[feat_config.index_cols+[feat_config.target]+['time_idx']].copy()\n",
    "# pred_df.set_index(feat_config.index_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c119fd2c-ceeb-46e7-a9d0-40fc49186167",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = feat_config.index_cols + [feat_config.target]\n",
    "full_df = pd.concat(\n",
    "    [\n",
    "        train_df[cols],\n",
    "        val_df[cols],\n",
    "    ]\n",
    ").set_index(feat_config.index_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066650ee-e2d6-485c-b1f6-5549b7a466cc",
   "metadata": {},
   "source": [
    "### Converting data into TimeSeriesDataset from PyTorch Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e312c5ad-9b02-450f-a3c6-931e918a2f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training dataset\n",
    "training = TimeSeriesDataSet(\n",
    "    train_df,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=feat_config.target,\n",
    "    group_ids=feat_config.group_ids,\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    # static_categoricals=feat_config.static_categoricals,\n",
    "    # static_reals=feat_config.static_reals,\n",
    "    time_varying_known_categoricals=feat_config.time_varying_known_categoricals,\n",
    "    # time_varying_known_reals=feat_config.time_varying_known_reals,\n",
    "    time_varying_unknown_reals=[\n",
    "        \"energy_consumption\",\n",
    "    ],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=feat_config.group_ids, transformation=None\n",
    "    )\n",
    ")\n",
    "# Defining the validation dataset with the same parameters as training\n",
    "validation = TimeSeriesDataSet.from_dataset(training, pd.concat([val_history,val_df]).reset_index(drop=True), stop_randomization=True)\n",
    "# Defining the test dataset with the same parameters as training\n",
    "test = TimeSeriesDataSet.from_dataset(training, pd.concat([hist_df, test_df]).reset_index(drop=True), stop_randomization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f82e3fd6-8041-40ae-b0b9-608abe7bd75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the dataloaders\n",
    "# num_workers can be increased in linux to speed-up training\n",
    "train_dataloader = training.to_dataloader(train=True, batch_size=batch_size, num_workers=0)\n",
    "val_dataloader = validation.to_dataloader(train=False, batch_size=batch_size, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db1506f5-1100-4edb-8868-7a7cca134aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sizes of x =\n",
      "\tencoder_cat = torch.Size([512, 96, 2])\n",
      "\tencoder_cont = torch.Size([512, 96, 1])\n",
      "\tencoder_target = torch.Size([512, 96])\n",
      "\tencoder_lengths = torch.Size([512])\n",
      "\tdecoder_cat = torch.Size([512, 48, 2])\n",
      "\tdecoder_cont = torch.Size([512, 48, 1])\n",
      "\tdecoder_target = torch.Size([512, 48])\n",
      "\tdecoder_lengths = torch.Size([512])\n",
      "\tdecoder_time_idx = torch.Size([512, 48])\n",
      "\tgroups = torch.Size([512, 1])\n",
      "\ttarget_scale = torch.Size([512, 2])\n",
      "\n",
      "size of y =\n",
      "\ty = torch.Size([512, 48])\n"
     ]
    }
   ],
   "source": [
    "# Testing the dataloader\n",
    "x, y = next(iter(train_dataloader))\n",
    "print(\"\\nsizes of x =\")\n",
    "for key, value in x.items():\n",
    "    print(f\"\\t{key} = {value.size()}\")\n",
    "print(\"\\nsize of y =\")\n",
    "print(f\"\\ty = {y[0].size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db207603-dcf8-4d03-aa29-2b2fce662826",
   "metadata": {},
   "source": [
    "### Initializing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cc0d756f-588b-4ee8-a41f-8025e41a5573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the skeleton and helper models from src\n",
    "from pytorch_forecasting.models import NHiTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "10c72e39-6b71-4e63-a5cb-69e6b2bd3c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.dl.ptf_models import InformerModel\n",
    "\n",
    "model_params = {}\n",
    "model_params['label_len'] = max_encoder_length//2\n",
    "model_params['distil'] = True\n",
    "model_params['d_model'] = 256\n",
    "model_params['dropout'] = 0.05\n",
    "model_params['factor'] = 1\n",
    "model_params['n_heads'] = 4\n",
    "model_params['d_ff'] = 512\n",
    "model_params['activation'] = 'gelu'\n",
    "model_params['e_layers'] = 2 \n",
    "model_params['d_layers'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1ab58b50-17cb-44d2-8aba-b8c97a68198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_params = dict(\n",
    "    learning_rate=1e-4,\n",
    "    optimizer=\"adam\",\n",
    "    loss=RMSE(),\n",
    "    logging_metrics=[RMSE(), MAE()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "146fced5-e902-44a0-9841-2c59e698cdc1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(pytorch_forecasting.utils.TupleOutputMixIn.to_network_output.<locals>.Output,\n",
       " torch.Size([512, 48, 1]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = InformerModel.from_dataset(\n",
    "    training,**{**model_params, **other_params})\n",
    "#Testing out the model\n",
    "x, y = next(iter(train_dataloader))\n",
    "_ = model(x)\n",
    "type(_), _.prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75796f18-565a-481d-934c-4a6558e46017",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d128ef61-f854-4436-a7f6-25447858548e",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model_sampled = f'notebooks/Chapter15/saved_weights/{tag}_sampled.wt'\n",
    "saved_model_full = f'notebooks/Chapter15/saved_weights/{tag}.wt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d5a93e8-99a2-467a-816f-a3f89ebfd3ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | RMSE       | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | network         | Informer   | 2.1 M \n",
      "-----------------------------------------------\n",
      "2.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 M     Total params\n",
      "8.220     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ManuJoseph\\miniconda3\\envs\\modern_ts_v3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "Global seed set to 42\n",
      "C:\\Users\\ManuJoseph\\miniconda3\\envs\\modern_ts_v3\\lib\\site-packages\\pytorch_lightning\\trainer\\data_loading.py:132: UserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 16 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3080e630de4726a8000575d39c3c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the best model from: C:\\Users\\ManuJoseph\\OneDrive - Thoucentric\\Work\\Projects\\Playground\\AdvancedTimeSeriesForecastingBook\\Github\\Modern-Time-Series-Forecasting-with-Python-\\lightning_logs\\version_96\\checkpoints\\epoch=1-step=1155.ckpt\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'saved_model_sampled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m     best_model \u001b[38;5;241m=\u001b[39m InformerModel\u001b[38;5;241m.\u001b[39mload_from_checkpoint(best_model_path)\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading the best model from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbest_model_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m     shutil\u001b[38;5;241m.\u001b[39mcopy(best_model_path, \u001b[43msaved_model_sampled\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m TRAIN_SUBSAMPLE \u001b[38;5;28;01melse\u001b[39;00m saved_model_full)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m     best_model_path \u001b[38;5;241m=\u001b[39m saved_model_sampled \u001b[38;5;28;01mif\u001b[39;00m TRAIN_SUBSAMPLE \u001b[38;5;28;01melse\u001b[39;00m saved_model_full\n",
      "\u001b[1;31mNameError\u001b[0m: name 'saved_model_sampled' is not defined"
     ]
    }
   ],
   "source": [
    "if train_model:\n",
    "    trainer = pl.Trainer(\n",
    "        auto_select_gpus=True,\n",
    "        gpus=-1,\n",
    "        min_epochs=1,\n",
    "        max_epochs=20,\n",
    "        callbacks=[\n",
    "            pl.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3 if TRAIN_SUBSAMPLE else 4*3),\n",
    "            pl.callbacks.ModelCheckpoint(\n",
    "                monitor=\"val_loss\", save_last=True, mode=\"min\", auto_insert_metric_name=True\n",
    "            ),\n",
    "        ],\n",
    "        val_check_interval=1.0 if TRAIN_SUBSAMPLE else 2000,\n",
    "        log_every_n_steps=50 if TRAIN_SUBSAMPLE else 2000,\n",
    "    )\n",
    "    trainer.fit(\n",
    "        model,\n",
    "        train_dataloaders=train_dataloader,\n",
    "        val_dataloaders=val_dataloader,\n",
    "    )\n",
    "    #Loading the best model\n",
    "    best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "    best_model = InformerModel.load_from_checkpoint(best_model_path)\n",
    "    print(f\"Loading the best model from: {best_model_path}\")\n",
    "    shutil.copy(best_model_path, saved_model_sampled if TRAIN_SUBSAMPLE else saved_model_full)\n",
    "else:\n",
    "    best_model_path = saved_model_sampled if TRAIN_SUBSAMPLE else saved_model_full\n",
    "    load_weights(model, best_model_path)\n",
    "    best_model =  model\n",
    "    print (\"Skipping Training and loading the model from {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "763f7ea8-3886-4ef7-a6fb-8a50fd91508c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for InformerModel:\n\tMissing key(s) in state_dict: \"network.enc_embedding.value_embedding.tokenConv.weight\", \"network.enc_embedding.position_embedding.pe\", \"network.enc_embedding.temporal_embedding.embeds.0.weight\", \"network.enc_embedding.temporal_embedding.embeds.1.weight\", \"network.dec_embedding.value_embedding.tokenConv.weight\", \"network.dec_embedding.position_embedding.pe\", \"network.dec_embedding.temporal_embedding.embeds.0.weight\", \"network.dec_embedding.temporal_embedding.embeds.1.weight\", \"network.encoder.attn_layers.0.attention.query_projection.weight\", \"network.encoder.attn_layers.0.attention.query_projection.bias\", \"network.encoder.attn_layers.0.attention.key_projection.weight\", \"network.encoder.attn_layers.0.attention.key_projection.bias\", \"network.encoder.attn_layers.0.attention.value_projection.weight\", \"network.encoder.attn_layers.0.attention.value_projection.bias\", \"network.encoder.attn_layers.0.attention.out_projection.weight\", \"network.encoder.attn_layers.0.attention.out_projection.bias\", \"network.encoder.attn_layers.0.conv1.weight\", \"network.encoder.attn_layers.0.conv1.bias\", \"network.encoder.attn_layers.0.conv2.weight\", \"network.encoder.attn_layers.0.conv2.bias\", \"network.encoder.attn_layers.0.norm1.weight\", \"network.encoder.attn_layers.0.norm1.bias\", \"network.encoder.attn_layers.0.norm2.weight\", \"network.encoder.attn_layers.0.norm2.bias\", \"network.encoder.attn_layers.1.attention.query_projection.weight\", \"network.encoder.attn_layers.1.attention.query_projection.bias\", \"network.encoder.attn_layers.1.attention.key_projection.weight\", \"network.encoder.attn_layers.1.attention.key_projection.bias\", \"network.encoder.attn_layers.1.attention.value_projection.weight\", \"network.encoder.attn_layers.1.attention.value_projection.bias\", \"network.encoder.attn_layers.1.attention.out_projection.weight\", \"network.encoder.attn_layers.1.attention.out_projection.bias\", \"network.encoder.attn_layers.1.conv1.weight\", \"network.encoder.attn_layers.1.conv1.bias\", \"network.encoder.attn_layers.1.conv2.weight\", \"network.encoder.attn_layers.1.conv2.bias\", \"network.encoder.attn_layers.1.norm1.weight\", \"network.encoder.attn_layers.1.norm1.bias\", \"network.encoder.attn_layers.1.norm2.weight\", \"network.encoder.attn_layers.1.norm2.bias\", \"network.encoder.conv_layers.0.downConv.weight\", \"network.encoder.conv_layers.0.downConv.bias\", \"network.encoder.conv_layers.0.norm.weight\", \"network.encoder.conv_layers.0.norm.bias\", \"network.encoder.conv_layers.0.norm.running_mean\", \"network.encoder.conv_layers.0.norm.running_var\", \"network.encoder.norm.weight\", \"network.encoder.norm.bias\", \"network.decoder.layers.0.self_attention.query_projection.weight\", \"network.decoder.layers.0.self_attention.query_projection.bias\", \"network.decoder.layers.0.self_attention.key_projection.weight\", \"network.decoder.layers.0.self_attention.key_projection.bias\", \"network.decoder.layers.0.self_attention.value_projection.weight\", \"network.decoder.layers.0.self_attention.value_projection.bias\", \"network.decoder.layers.0.self_attention.out_projection.weight\", \"network.decoder.layers.0.self_attention.out_projection.bias\", \"network.decoder.layers.0.cross_attention.query_projection.weight\", \"network.decoder.layers.0.cross_attention.query_projection.bias\", \"network.decoder.layers.0.cross_attention.key_projection.weight\", \"network.decoder.layers.0.cross_attention.key_projection.bias\", \"network.decoder.layers.0.cross_attention.value_projection.weight\", \"network.decoder.layers.0.cross_attention.value_projection.bias\", \"network.decoder.layers.0.cross_attention.out_projection.weight\", \"network.decoder.layers.0.cross_attention.out_projection.bias\", \"network.decoder.layers.0.conv1.weight\", \"network.decoder.layers.0.conv1.bias\", \"network.decoder.layers.0.conv2.weight\", \"network.decoder.layers.0.conv2.bias\", \"network.decoder.layers.0.norm1.weight\", \"network.decoder.layers.0.norm1.bias\", \"network.decoder.layers.0.norm2.weight\", \"network.decoder.layers.0.norm2.bias\", \"network.decoder.layers.0.norm3.weight\", \"network.decoder.layers.0.norm3.bias\", \"network.decoder.norm.weight\", \"network.decoder.norm.bias\", \"network.decoder.projection.weight\", \"network.decoder.projection.bias\". \n\tUnexpected key(s) in state_dict: \"epoch\", \"global_step\", \"pytorch-lightning_version\", \"state_dict\", \"callbacks\", \"optimizer_states\", \"lr_schedulers\", \"hparams_name\", \"hyper_parameters\", \"dataset_parameters\", \"__special_save__\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [40]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbest_model_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m best_model \u001b[38;5;241m=\u001b[39m model\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mload_weights\u001b[1;34m(model, weight_path)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_weights\u001b[39m(model, weight_path):\n\u001b[0;32m     66\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m pl_load(weight_path)\n\u001b[1;32m---> 67\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\modern_ts_v3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1497\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1492\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   1493\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1494\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1497\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1498\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for InformerModel:\n\tMissing key(s) in state_dict: \"network.enc_embedding.value_embedding.tokenConv.weight\", \"network.enc_embedding.position_embedding.pe\", \"network.enc_embedding.temporal_embedding.embeds.0.weight\", \"network.enc_embedding.temporal_embedding.embeds.1.weight\", \"network.dec_embedding.value_embedding.tokenConv.weight\", \"network.dec_embedding.position_embedding.pe\", \"network.dec_embedding.temporal_embedding.embeds.0.weight\", \"network.dec_embedding.temporal_embedding.embeds.1.weight\", \"network.encoder.attn_layers.0.attention.query_projection.weight\", \"network.encoder.attn_layers.0.attention.query_projection.bias\", \"network.encoder.attn_layers.0.attention.key_projection.weight\", \"network.encoder.attn_layers.0.attention.key_projection.bias\", \"network.encoder.attn_layers.0.attention.value_projection.weight\", \"network.encoder.attn_layers.0.attention.value_projection.bias\", \"network.encoder.attn_layers.0.attention.out_projection.weight\", \"network.encoder.attn_layers.0.attention.out_projection.bias\", \"network.encoder.attn_layers.0.conv1.weight\", \"network.encoder.attn_layers.0.conv1.bias\", \"network.encoder.attn_layers.0.conv2.weight\", \"network.encoder.attn_layers.0.conv2.bias\", \"network.encoder.attn_layers.0.norm1.weight\", \"network.encoder.attn_layers.0.norm1.bias\", \"network.encoder.attn_layers.0.norm2.weight\", \"network.encoder.attn_layers.0.norm2.bias\", \"network.encoder.attn_layers.1.attention.query_projection.weight\", \"network.encoder.attn_layers.1.attention.query_projection.bias\", \"network.encoder.attn_layers.1.attention.key_projection.weight\", \"network.encoder.attn_layers.1.attention.key_projection.bias\", \"network.encoder.attn_layers.1.attention.value_projection.weight\", \"network.encoder.attn_layers.1.attention.value_projection.bias\", \"network.encoder.attn_layers.1.attention.out_projection.weight\", \"network.encoder.attn_layers.1.attention.out_projection.bias\", \"network.encoder.attn_layers.1.conv1.weight\", \"network.encoder.attn_layers.1.conv1.bias\", \"network.encoder.attn_layers.1.conv2.weight\", \"network.encoder.attn_layers.1.conv2.bias\", \"network.encoder.attn_layers.1.norm1.weight\", \"network.encoder.attn_layers.1.norm1.bias\", \"network.encoder.attn_layers.1.norm2.weight\", \"network.encoder.attn_layers.1.norm2.bias\", \"network.encoder.conv_layers.0.downConv.weight\", \"network.encoder.conv_layers.0.downConv.bias\", \"network.encoder.conv_layers.0.norm.weight\", \"network.encoder.conv_layers.0.norm.bias\", \"network.encoder.conv_layers.0.norm.running_mean\", \"network.encoder.conv_layers.0.norm.running_var\", \"network.encoder.norm.weight\", \"network.encoder.norm.bias\", \"network.decoder.layers.0.self_attention.query_projection.weight\", \"network.decoder.layers.0.self_attention.query_projection.bias\", \"network.decoder.layers.0.self_attention.key_projection.weight\", \"network.decoder.layers.0.self_attention.key_projection.bias\", \"network.decoder.layers.0.self_attention.value_projection.weight\", \"network.decoder.layers.0.self_attention.value_projection.bias\", \"network.decoder.layers.0.self_attention.out_projection.weight\", \"network.decoder.layers.0.self_attention.out_projection.bias\", \"network.decoder.layers.0.cross_attention.query_projection.weight\", \"network.decoder.layers.0.cross_attention.query_projection.bias\", \"network.decoder.layers.0.cross_attention.key_projection.weight\", \"network.decoder.layers.0.cross_attention.key_projection.bias\", \"network.decoder.layers.0.cross_attention.value_projection.weight\", \"network.decoder.layers.0.cross_attention.value_projection.bias\", \"network.decoder.layers.0.cross_attention.out_projection.weight\", \"network.decoder.layers.0.cross_attention.out_projection.bias\", \"network.decoder.layers.0.conv1.weight\", \"network.decoder.layers.0.conv1.bias\", \"network.decoder.layers.0.conv2.weight\", \"network.decoder.layers.0.conv2.bias\", \"network.decoder.layers.0.norm1.weight\", \"network.decoder.layers.0.norm1.bias\", \"network.decoder.layers.0.norm2.weight\", \"network.decoder.layers.0.norm2.bias\", \"network.decoder.layers.0.norm3.weight\", \"network.decoder.layers.0.norm3.bias\", \"network.decoder.norm.weight\", \"network.decoder.norm.bias\", \"network.decoder.projection.weight\", \"network.decoder.projection.bias\". \n\tUnexpected key(s) in state_dict: \"epoch\", \"global_step\", \"pytorch-lightning_version\", \"state_dict\", \"callbacks\", \"optimizer_states\", \"lr_schedulers\", \"hparams_name\", \"hyper_parameters\", \"dataset_parameters\", \"__special_save__\". "
     ]
    }
   ],
   "source": [
    "# load_weights(model,best_model_path)\n",
    "# best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81690830-7dbd-48d2-9a7e-762562f4ae31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d552335c1b5944359e296d176295ad02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predict:   0%|          | 0/226 [00:00<?, ? batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f856c5c3147746aa91b2a1c6cba15c91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating metrics...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred, index = best_model.predict(test, return_index=True, show_progress_bar=True)\n",
    "index[[f\"{tag}_step_{i}\" for i in range(pred.shape[-1])]] = pred\n",
    "pred_df = (\n",
    "    pred_df.reset_index()\n",
    "    .merge(\n",
    "        index[[\"time_idx\", \"LCLid\", f\"{tag}_step_0\"]],\n",
    "        on=[\"time_idx\", \"LCLid\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .dropna(subset=[\"LCLid\", f\"{tag}_step_0\"]) # Last 48 timesteps do not have a one step FC because single multi-step FC covered it\n",
    "    .set_index(feat_config.index_cols)\n",
    ")\n",
    "# Evaluating the forecast\n",
    "agg_metrics, eval_metrics_df = evaluate_forecast(\n",
    "    pred_df = pred_df,\n",
    "    train_data = full_df,\n",
    "    fc_column=f\"{tag}_step_0\",\n",
    "    name=f\"{tag}_step_0\",\n",
    ")\n",
    "metric_record.append(agg_metrics)\n",
    "individual_metrics[f\"{tag}_step_0\"]=eval_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "26e371c8-1c33-48a6-90d9-6802f1743b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df = pred_df.drop(columns=[\"N-BEATS(I)_single_step\", \"N-BEATS(I)_one_day_x\"]).rename(columns={\"N-BEATS(I)_one_day_y\": \"N-BEATS(I)_one_day\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "08b06572-2a53-47c5-be8e-f778d5d6f388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4531b4ea21b477681288c3dd1e46b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating metrics...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = index.groupby(\"LCLid\").apply(create_one_day_ahead_fc)\n",
    "pred_df = (\n",
    "    pred_df.reset_index()\n",
    "    .merge(\n",
    "        index[[\"time_idx\", \"LCLid\", f\"{tag}_one_day\"]],\n",
    "        on=[\"time_idx\", \"LCLid\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    .set_index(feat_config.index_cols)\n",
    ")\n",
    "# Evaluating the forecast\n",
    "agg_metrics, eval_metrics_df = evaluate_forecast(\n",
    "    pred_df=pred_df,\n",
    "    train_data=full_df,\n",
    "    fc_column=f\"{tag}_one_day\",\n",
    "    name=f\"{tag}_one_day\",\n",
    ")\n",
    "metric_record.append(agg_metrics)\n",
    "individual_metrics[f\"{tag}_one_day\"] = eval_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05642f66-f785-4a2e-b242-79cf518081e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>meanMASE</th>\n",
       "      <th>Forecast Bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Informer_step_0</td>\n",
       "      <td>0.086745</td>\n",
       "      <td>0.025608</td>\n",
       "      <td>1.002191</td>\n",
       "      <td>-7.940187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Informer_one_day</td>\n",
       "      <td>0.106899</td>\n",
       "      <td>0.037204</td>\n",
       "      <td>1.215612</td>\n",
       "      <td>-15.277581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Algorithm       MAE       MSE  meanMASE  Forecast Bias\n",
       "0   Informer_step_0  0.086745  0.025608  1.002191      -7.940187\n",
       "1  Informer_one_day  0.106899  0.037204  1.215612     -15.277581"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metric_record)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
